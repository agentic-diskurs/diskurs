import copy
import enum
import importlib
from typing import Any, Optional, TypeVar

from diskurs.entities import ChatMessage, LongtermMemory, MessageType, ResultHolder, Role
from diskurs.protocols import Conversation, ConversationStore
from diskurs.registry import register_conversation

GenericPrompt = TypeVar("GenericPrompt", bound="Prompt")
GenericPromptArg = TypeVar("GenericPromptArg", bound="PromptArgument")


@register_conversation("immutable_conversation")
class ImmutableConversation(Conversation):

    def __init__(
        self,
        metadata: Optional[dict[str, str | enum.Enum]] = None,
        chat: Optional[list[ChatMessage]] = None,
        prompt_argument: Optional[GenericPromptArg] = None,
        system_prompt: Optional[ChatMessage] = None,
        user_prompt: Optional[ChatMessage | list[ChatMessage]] = None,
        active_agent: Optional[str] = None,
        conversation_id: Optional[str] = None,
        conversation_store: Optional[ConversationStore] = None,
        final_result: Optional[dict[str, Any]] = None,
        longterm_memory: Optional[LongtermMemory] = None,
    ):
        """
        Initialize an immutable conversation object.

        :param metadata: Optional metadata dictionary.
        :param chat: Chat history.
        :param prompt_argument: Current prompt argument.
        :param system_prompt: System prompt.
        :param user_prompt: User prompt.
        :param active_agent: Name of the active agent.
        :param conversation_id: Unique conversation ID.
        :param conversation_store: Conversation store for persistence.
        :param final_result: Optional final result dictionary.
        :param longterm_memory: Global longterm memory for the conversation.
        """
        self._metadata = metadata or {}
        self._chat = chat or []
        self._prompt_argument = prompt_argument
        self._system_prompt = system_prompt
        self._user_prompt = user_prompt
        self._active_agent = active_agent
        self._conversation_id = conversation_id
        self._longterm_memory = longterm_memory
        self._conversation_store = conversation_store
        self._final_result = final_result or ResultHolder()
        self.conversation_store = conversation_store

    @property
    def final_result(self) -> dict[str, Any]:
        """
        Retrieves the final result of the conversation.

        The final result is a dictionary containing the data representing the outcome
        of the conversation. It is typically generated by the conductor agent when the
        conversation reaches a final state.

        :return: The final result of the conversation if available, otherwise None.
        """
        return self._final_result.result

    @final_result.setter
    def final_result(self, value: dict[str, Any]) -> None:
        """
        Takes the value, unpacks it and assigns its items to the final_result attribute.
        This ensures that the final_result maintains the same reference, thereby being the
        only attribute of the Conversation class that is explicitly not immutable.

        :param value: A dictionary containing the final result of the conversation.
        """
        self._final_result.result = value

    @property
    def conversation_id(self) -> str:
        return self._conversation_id

    @conversation_id.setter
    def conversation_id(self, value):
        self._conversation_id = value

    @property
    def active_agent(self):
        return self._active_agent

    @active_agent.setter
    def active_agent(self, value):
        self._active_agent = value

    @property
    def chat(self) -> list[ChatMessage]:
        return copy.deepcopy(self._chat)

    @property
    def system_prompt(self) -> ChatMessage:
        return self._system_prompt

    @property
    def user_prompt(self) -> ChatMessage | list[ChatMessage]:
        return self._user_prompt

    @property
    def prompt_argument(self) -> GenericPromptArg:
        return copy.deepcopy(self._prompt_argument)

    @property
    def metadata(self) -> dict[str, str | enum.Enum]:
        return copy.deepcopy(self._metadata)

    @property
    def last_message(self) -> ChatMessage:
        if not self.is_empty():
            return copy.deepcopy(self._chat[-1])
        else:
            raise ValueError("The chat is empty.")

    @property
    def longterm_memory(self) -> "LongtermMemory":
        """
        Returns a copy of the global longterm memory.

        :return: Copy of the global longterm memory
        """
        return copy.deepcopy(self._longterm_memory)

    def get_agent_longterm_memory(self, agent_name: str) -> "LongtermMemory":
        """
        Returns the global longterm memory.
        This method is maintained for backward compatibility.

        :param agent_name: Ignored in the new implementation
        :return: Copy of the global longterm memory
        """
        return copy.deepcopy(self._longterm_memory)

    def update_agent_longterm_memory(
        self, agent_name: str, longterm_memory: "LongtermMemory"
    ) -> "ImmutableConversation":
        """
        Updates the global longterm memory.
        This method is maintained for backward compatibility.

        :param agent_name: Ignored in the new implementation
        :param longterm_memory: The new longterm memory
        :return: A new ImmutableConversation with updated longterm memory
        """
        return self.update(longterm_memory=longterm_memory)

    def update(
        self,
        chat: Optional[list[ChatMessage]] = None,
        prompt_argument: Optional[GenericPromptArg] = None,
        system_prompt: Optional[ChatMessage] = None,
        user_prompt: Optional[ChatMessage | list[ChatMessage]] = None,
        longterm_memory: Optional["LongtermMemory"] = None,
        metadata: Optional[dict[str, str | enum.Enum]] = None,
        active_agent: Optional[str] = None,
        conversation_id: Optional[str] = None,
    ) -> "ImmutableConversation":
        return ImmutableConversation(
            system_prompt=(system_prompt or self._system_prompt),
            user_prompt=user_prompt or self._user_prompt,
            prompt_argument=prompt_argument or self._prompt_argument,
            chat=chat or self._chat,
            longterm_memory=longterm_memory or self._longterm_memory,
            metadata=metadata or self._metadata,
            active_agent=active_agent or self.active_agent,
            conversation_id=conversation_id or self._conversation_id,
            final_result=self._final_result,
            conversation_store=self.conversation_store,
        )

    def append(
        self,
        message: ChatMessage | list[ChatMessage],
        role: Optional[Role] = "",
        name: Optional[str] = "",
    ) -> "ImmutableConversation":
        """
        Appends a new chat message and returns a new instance of Conversation.

        :param message: The ChatMessage object to be added to the conversation, alternatively a string can be provided.
        :param role: Only needed if message is str, the role (system, user, assistant)
        :param name: Only needed if message is str, name of the agent
        :return: A new instance of Conversation with the appended message.
        """
        if isinstance(message, str):
            new_message = [ChatMessage(content=message, role=role, name=name)]
        elif isinstance(message, ChatMessage):
            new_message = [message]
        elif isinstance(message, list) and all(isinstance(m, ChatMessage) for m in message):
            new_message = message
        else:
            raise ValueError("Invalid message type. Must be a string, ChatMessage or a list of ChatMessages")

        new_chat = self.chat + new_message

        return self.update(chat=new_chat)

    def render_chat(self, message_type: MessageType = MessageType.CONVERSATION) -> list[ChatMessage]:
        if message_type == MessageType.CONVERSATION:
            chat = [message for message in self.chat if message.type == message_type]
        elif message_type == MessageType.CONDUCTOR:
            chat = self.chat
        else:
            raise ValueError(f"Invalid message type: {message_type}")

        result = []

        if self.system_prompt is not None:
            result.append(self.system_prompt)

        result.extend(chat)

        if self.user_prompt is not None:
            if isinstance(self.user_prompt, list):
                result.extend(self.user_prompt)
            else:
                result.append(self.user_prompt)

        return result

    def is_empty(self) -> bool:
        return len(self._chat) == 0

    def has_pending_tool_call(self):
        if not self.is_empty():
            last_message = self._chat[-1]
            return last_message.role == Role.ASSISTANT and last_message.tool_calls
        else:
            return False

    def has_pending_tool_response(self) -> bool:
        user_prompt = self.user_prompt if isinstance(self.user_prompt, list) else [self.user_prompt]
        if not any(user_prompt):
            return False
        else:
            return any([msg.role == Role.TOOL for msg in user_prompt])

    def __setattr__(self, key, value):
        if key in self.__dict__:
            raise AttributeError(f"{key} is immutable and cannot be changed")
        super().__setattr__(key, value)

    @classmethod
    def from_dict(
        cls,
        data: dict[str, Any],
        agents: list,
        longterm_memory_class: Optional[LongtermMemory] = None,
        conversation_store: Optional[ConversationStore] = None,
    ) -> "ImmutableConversation":
        active_agent = next(agent for agent in agents if agent.name == data["active_agent"])

        prompt_argument = active_agent.prompt.prompt_argument
        prompt_argument = (
            prompt_argument.from_dict(
                data["prompt_argument"],
            )
            if data["prompt_argument"]
            else None
        )

        system_prompt = ChatMessage.from_dict(data["system_prompt"]) if data["system_prompt"] else None
        user_prompt = ChatMessage.from_dict(data["user_prompt"]) if data["user_prompt"] else None

        # If no longterm_memory_class is provided, try to get it from active agent
        if longterm_memory_class is None:
            # Try to get longterm_memory_class from active agent or one of the other agents
            for agent in agents:
                try:
                    if hasattr(agent.prompt, "longterm_memory"):
                        longterm_memory_class = agent.prompt.longterm_memory
                        if longterm_memory_class is not None:
                            break
                except (AttributeError, TypeError):
                    continue

            # If we still don't have a longterm_memory_class, use the base LongtermMemory
            if longterm_memory_class is None:
                from diskurs.entities import LongtermMemory

                longterm_memory_class = LongtermMemory

        # Handle backward compatibility - if data["longterm_memory"] is a dict with agent names as keys
        longterm_memory_data = data.get("longterm_memory", {})
        if isinstance(longterm_memory_data, dict) and any(agent.name in longterm_memory_data for agent in agents):
            # For backward compatibility, construct a single memory from the first agent memory
            agent_name = next(
                name for name in longterm_memory_data.keys() if any(agent.name == name for agent in agents)
            )
            longterm_memory = longterm_memory_class.from_dict(longterm_memory_data.get(agent_name, {}))
        else:
            # Use the regular approach for the new format
            longterm_memory = longterm_memory_class.from_dict(longterm_memory_data)

        # Process metadata to deserialize enums
        metadata = data.get("metadata", {})
        for k, v in list(metadata.items()):
            if isinstance(v, dict) and v.get("__enum__") is True:
                try:
                    # Import the enum class dynamically
                    module = importlib.import_module(v["module"])
                    enum_class = getattr(module, v["class"])
                    # Get the enum value by name
                    metadata[k] = getattr(enum_class, v["value"])
                except (ImportError, AttributeError) as e:
                    # If the enum class or value can't be found, keep the serialized representation
                    pass

        return cls(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            prompt_argument=prompt_argument,
            chat=[ChatMessage.from_dict(msg) for msg in data.get("chat", [])],
            longterm_memory=longterm_memory,
            metadata=metadata,
            active_agent=data["active_agent"],
            conversation_id=data.get("conversation_id", ""),
            conversation_store=conversation_store,
        )

    def to_dict(self) -> dict[str, Any]:
        # Helper to handle enum serialization
        def process_metadata(md):
            processed = {}
            for k, v in md.items():
                if isinstance(v, enum.Enum):
                    # Store enum as tuple: (enum class name, enum value name)
                    processed[k] = {
                        "__enum__": True,
                        "module": v.__class__.__module__,
                        "class": v.__class__.__name__,
                        "value": v.name,
                    }
                else:
                    processed[k] = v
            return processed

        return {
            "system_prompt": (self.system_prompt.to_dict() if self.system_prompt else None),
            "user_prompt": (self.user_prompt.to_dict() if self.user_prompt else None),
            "prompt_argument": (self.prompt_argument.to_dict() if self.prompt_argument else None),
            "chat": [msg.to_dict() for msg in self.chat],
            "longterm_memory": (self._longterm_memory.to_dict() if self._longterm_memory else {}),
            "metadata": process_metadata(self.metadata),
            "active_agent": self.active_agent,
            "conversation_id": self.conversation_id,
        }

    async def maybe_persist(self) -> None:
        """
        Persists the conversation if a persistent conversation store is available
        and a conversation ID is set.
        """
        if self.conversation_store and self.conversation_id:
            await self.conversation_store.persist(self)

    def is_previous_agent_conductor(self):
        if self.is_empty():
            return False
        else:
            return self.last_message.type == MessageType.CONDUCTOR

    def get_last_conductor_name(self) -> Optional[str]:
        for message in reversed(self.chat):
            if message.type == MessageType.CONDUCTOR:
                return message.name
        return None

    def has_conductor_been_called(self):
        return any(message.type == MessageType.CONDUCTOR for message in self.chat)

    def update_longterm_memory(self, prompt_argument: GenericPromptArg) -> "ImmutableConversation":
        """
        Updates the global longterm memory using values from a PromptArgument.
        Only fields of type OutputField in the PromptArgument will be copied to
        the LongtermMemory if they have matching names.

        :param prompt_argument: The prompt argument to extract output fields from
        :return: A new ImmutableConversation with updated longterm memory
        """
        updated_memory = self.longterm_memory.update(prompt_argument)
        return self.update(longterm_memory=updated_memory)
