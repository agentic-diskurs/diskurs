import copy
import enum
import importlib
from dataclasses import fields, replace
from typing import Any, Optional, TypeVar

from diskurs import LongtermMemory
from diskurs.entities import ChatMessage, MessageType, ResultHolder, Role
from diskurs.protocols import Conversation, ConversationStore
from diskurs.registry import register_conversation

GenericPrompt = TypeVar("GenericPrompt", bound="Prompt")
GenericPromptArg = TypeVar("GenericPromptArg", bound="PromptArgument")


@register_conversation("immutable_conversation")
class ImmutableConversation(Conversation):

    def __init__(
        self,
        system_prompt: Optional[ChatMessage] = None,
        user_prompt: Optional[ChatMessage] = None,
        prompt_argument: Optional[GenericPromptArg] = None,
        chat=None,
        longterm_memory: Optional[dict[str, "LongtermMemory"]] = None,
        metadata: Optional[dict[str, str | enum.Enum]] = None,
        active_agent: str = "",
        conversation_id="",
        final_result: Optional[dict[str, Any]] = None,
        conversation_store: Optional[ConversationStore] = None,
    ):
        if chat is None:
            self._chat = []
        else:
            self._chat = copy.deepcopy(chat)

        self._system_prompt = copy.deepcopy(system_prompt) if system_prompt else None
        self._user_prompt = copy.deepcopy(user_prompt) if user_prompt else None
        self._prompt_argument = copy.deepcopy(prompt_argument) if prompt_argument else None
        self._longterm_memory = copy.deepcopy(longterm_memory) or {}
        self._metadata = copy.deepcopy(metadata) or {}
        self._active_agent = active_agent
        self._conversation_id = conversation_id
        self._final_result = final_result or ResultHolder()
        self.conversation_store = conversation_store

    @property
    def final_result(self) -> dict[str, Any]:
        """
        Retrieves the final result of the conversation.

        The final result is a dictionary containing the data representing the outcome
        of the conversation. It is typically generated by the conductor agent when the
        conversation reaches a final state.

        :return: The final result of the conversation if available, otherwise None.
        """
        return self._final_result.result

    @final_result.setter
    def final_result(self, value: dict[str, Any]) -> None:
        """
        Takes the value, unpacks it and assigns its items to the final_result attribute.
        This ensures that the final_result maintains the same reference, thereby being the
        only attribute of the Conversation class that is explicitly not immutable.

        :param value: A dictionary containing the final result of the conversation.
        """
        self._final_result.result = value

    @property
    def conversation_id(self) -> str:
        return self._conversation_id

    @conversation_id.setter
    def conversation_id(self, value):
        self._conversation_id = value

    @property
    def active_agent(self):
        return self._active_agent

    @active_agent.setter
    def active_agent(self, value):
        self._active_agent = value

    @property
    def chat(self) -> list[ChatMessage]:
        return copy.deepcopy(self._chat)

    @property
    def system_prompt(self) -> ChatMessage:
        return self._system_prompt

    @property
    def user_prompt(self) -> ChatMessage:
        return self._user_prompt

    @property
    def prompt_argument(self) -> GenericPromptArg:
        return copy.deepcopy(self._prompt_argument)

    @property
    def metadata(self) -> dict[str, str | enum.Enum]:
        return copy.deepcopy(self._metadata)

    @property
    def last_message(self) -> ChatMessage:
        if not self.is_empty():
            return copy.deepcopy(self._chat[-1])
        else:
            raise ValueError("The chat is empty.")

    def get_agent_longterm_memory(self, agent_name: str) -> "LongtermMemory":
        return copy.deepcopy(self._longterm_memory.get(agent_name))

    def update_agent_longterm_memory(
        self, agent_name: str, longterm_memory: "LongtermMemory"
    ) -> "ImmutableConversation":
        updated_longterm_memory = copy.deepcopy(self._longterm_memory)
        updated_longterm_memory[agent_name] = longterm_memory

        return self.update(longterm_memory=updated_longterm_memory)

    @staticmethod
    def update_prompt_argument(source_values, target_values):
        updated_fields = {}
        for field in fields(target_values):
            if hasattr(source_values, field.name):
                source_value = getattr(source_values, field.name)
                if source_value:
                    updated_fields[field.name] = source_value
        updated_prompt_argument = replace(target_values, **updated_fields)
        return updated_prompt_argument

    def update_prompt_argument_with_longterm_memory(self, conductor_name: str) -> "ImmutableConversation":
        longterm_memory = self.get_agent_longterm_memory(conductor_name)
        updated_prompt_argument = self.update_prompt_argument(
            source_values=longterm_memory,
            target_values=self.prompt_argument,
        )

        return self.update(prompt_argument=updated_prompt_argument)

    def update_prompt_argument_with_previous_agent(
        self, previous_agent_prompt_argument: GenericPromptArg
    ) -> "ImmutableConversation":
        updated_prompt_argument = self.update_prompt_argument(
            source_values=previous_agent_prompt_argument,
            target_values=self.prompt_argument,
        )

        return self.update(prompt_argument=updated_prompt_argument)

    def update(
        self,
        chat: Optional[list[ChatMessage]] = None,
        prompt_argument: Optional[GenericPromptArg] = None,
        system_prompt: Optional[ChatMessage] = None,
        user_prompt: Optional[ChatMessage | list[ChatMessage]] = None,
        longterm_memory: Optional[dict[str, Any]] = None,
        metadata: Optional[dict[str, str | enum.Enum]] = None,
        active_agent: Optional[str] = None,
        conversation_id: Optional[str] = None,
    ) -> "ImmutableConversation":
        return ImmutableConversation(
            system_prompt=(system_prompt or self._system_prompt),
            user_prompt=user_prompt or self._user_prompt,
            prompt_argument=prompt_argument or self._prompt_argument,
            chat=chat or self._chat,
            longterm_memory=longterm_memory or self._longterm_memory,
            metadata=metadata or self._metadata,
            active_agent=active_agent or self.active_agent,
            conversation_id=conversation_id or self._conversation_id,
            final_result=self._final_result,
            conversation_store=self.conversation_store,
        )

    def append(
        self,
        message: ChatMessage | list[ChatMessage],
        role: Optional[Role] = "",
        name: Optional[str] = "",
    ) -> "ImmutableConversation":
        """
        Appends a new chat message and returns a new instance of Conversation.

        :param message: The ChatMessage object to be added to the conversation, alternatively a string can be provided.
        :param role: Only needed if message is str, the role (system, user, assistant)
        :param name: Only needed if message is str, name of the agent
        :return: A new instance of Conversation with the appended message.
        """
        if isinstance(message, str):
            new_message = [ChatMessage(content=message, role=role, name=name)]
        elif isinstance(message, ChatMessage):
            new_message = [message]
        elif isinstance(message, list) and all(isinstance(m, ChatMessage) for m in message):
            new_message = message
        else:
            raise ValueError("Invalid message type. Must be a string, ChatMessage or a list of ChatMessages")

        new_chat = self.chat + new_message

        return self.update(chat=new_chat)

    def render_chat(self, message_type: MessageType = MessageType.CONVERSATION) -> list[ChatMessage]:
        if message_type == MessageType.CONVERSATION:
            chat = [message for message in self.chat if message.type == message_type]
        elif message_type == MessageType.CONDUCTOR:
            chat = self.chat
        else:
            raise ValueError(f"Invalid message type: {message_type}")

        return [self.system_prompt] + chat + [self.user_prompt]

    def is_empty(self) -> bool:
        return len(self._chat) == 0

    def has_pending_tool_call(self):
        if not self.is_empty():
            last_message = self._chat[-1]
            return last_message.role == Role.ASSISTANT and last_message.tool_calls
        else:
            return False

    def has_pending_tool_response(self) -> bool:
        user_prompt = self.user_prompt if isinstance(self.user_prompt, list) else [self.user_prompt]
        if not any(user_prompt):
            return False
        else:
            return any([msg.role == Role.TOOL for msg in user_prompt])

    def __setattr__(self, key, value):
        if key in self.__dict__:
            raise AttributeError(f"{key} is immutable and cannot be changed")
        super().__setattr__(key, value)

    @classmethod
    def from_dict(
        cls,
        data: dict[str, Any],
        agents: list,
        conversation_store: Optional[ConversationStore] = None,
    ) -> "ImmutableConversation":
        active_agent = next(agent for agent in agents if agent.name == data["active_agent"])

        prompt_argument = active_agent.prompt.prompt_argument
        prompt_argument = prompt_argument.from_dict(data["prompt_argument"]) if data["prompt_argument"] else None

        system_prompt = ChatMessage.from_dict(data["system_prompt"]) if data["system_prompt"] else None
        user_prompt = ChatMessage.from_dict(data["user_prompt"]) if data["user_prompt"] else None

        ltm_cls_map = {
            conductor_name: [agent for agent in agents if agent.name == conductor_name][0].prompt.longterm_memory
            for conductor_name in data["longterm_memory"].keys()
        }
        longterm_memory = {k: ltm_cls_map[k].from_dict(v) for k, v in data.get("longterm_memory", {}).items()}

        # Process metadata to deserialize enums
        metadata = data.get("metadata", {})
        for k, v in list(metadata.items()):
            if isinstance(v, dict) and v.get("__enum__") is True:
                try:
                    # Import the enum class dynamically
                    module = importlib.import_module(v["module"])
                    enum_class = getattr(module, v["class"])
                    # Get the enum value by name
                    metadata[k] = getattr(enum_class, v["value"])
                except (ImportError, AttributeError) as e:
                    # If the enum class or value can't be found, keep the serialized representation
                    pass

        return cls(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            prompt_argument=prompt_argument,
            chat=[ChatMessage.from_dict(msg) for msg in data.get("chat", [])],
            longterm_memory=longterm_memory,
            metadata=metadata,
            active_agent=data["active_agent"],
            conversation_id=data.get("conversation_id", ""),
            conversation_store=conversation_store,
        )

    def to_dict(self) -> dict[str, Any]:
        # Helper to handle enum serialization
        def process_metadata(md):
            processed = {}
            for k, v in md.items():
                if isinstance(v, enum.Enum):
                    # Store enum as tuple: (enum class name, enum value name)
                    processed[k] = {
                        "__enum__": True,
                        "module": v.__class__.__module__,
                        "class": v.__class__.__name__,
                        "value": v.name,
                    }
                else:
                    processed[k] = v
            return processed

        return {
            "system_prompt": (self.system_prompt.to_dict() if self.system_prompt else None),
            "user_prompt": (self.user_prompt.to_dict() if self.user_prompt else None),
            "prompt_argument": (self.prompt_argument.to_dict() if self.prompt_argument else None),
            "chat": [msg.to_dict() for msg in self.chat],
            "longterm_memory": {k: v.to_dict() for k, v in self._longterm_memory.items()},
            "metadata": process_metadata(self.metadata),
            "active_agent": self.active_agent,
            "conversation_id": self.conversation_id,
        }

    async def maybe_persist(self) -> None:
        """
        Persists the conversation if a persistent conversation store is available
        and a conversation ID is set.
        """
        if self.conversation_store and self.conversation_id:
            await self.conversation_store.persist(self)
